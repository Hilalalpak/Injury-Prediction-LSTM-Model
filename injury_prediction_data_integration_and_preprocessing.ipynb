{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn5Y-CMXROC6"
      },
      "outputs": [],
      "source": [
        "############\n",
        "# LIBRARIES\n",
        "############\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Adjusting Row Column Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.set_option('display.width', 500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# READ DATA\n",
        "############\n",
        "\n",
        "game_workload_df = pd.read_csv(\"/content/drive/MyDrive/Injury Prediction/game_workload.csv\")\n",
        "injuries_df = pd.read_csv(\"/content/drive/MyDrive/Injury Prediction/injuries.csv\")\n",
        "metrics_df = pd.read_csv(\"/content/drive/MyDrive/Injury Prediction/metrics.csv\")"
      ],
      "metadata": {
        "id": "kYdfRN1BSA0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "# ASTYPE\n",
        "#########\n",
        "\n",
        "game_workload_df['date'] = pd.to_datetime(game_workload_df['date'])\n",
        "injuries_df['date'] = pd.to_datetime(injuries_df['date'])\n",
        "metrics_df['date'] = pd.to_datetime(metrics_df['date'])\n",
        "\n",
        "game_workload_df[\"athlete_id\"] = game_workload_df[\"athlete_id\"].astype(object)\n",
        "injuries_df[\"athlete_id\"] = injuries_df[\"athlete_id\"].astype(object)\n",
        "metrics_df[\"athlete_id\"] = metrics_df[\"athlete_id\"].astype(object)"
      ],
      "metadata": {
        "id": "YHTZczDOcPrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "# DATASET MERGING\n",
        "#################\n",
        "\n",
        "merged_df = pd.merge(metrics_df, game_workload_df, on=['athlete_id', 'date'], how='outer')\n",
        "\n",
        "\n",
        "injuries_df[\"injuries_status\"] = \"injured\"\n",
        "final_df = pd.merge(merged_df, injuries_df, on=['athlete_id', 'date'], how='outer')\n",
        "final_df['injuries_status'].fillna(\"non_injured\", inplace=True)\n",
        "\n",
        "\n",
        "#metrics_dates = set(metrics_df['date'])\n",
        "#workload_dates = set(game_workload_df['date'])\n",
        "\n",
        "#metrics_only_dates = metrics_dates - workload_dates\n",
        "#workload_only_dates = workload_dates - metrics_dates\n",
        "\n",
        "# len(metrics_only_dates) ## 24 different dates\n",
        "## game_workload data is missing because athletes have not trained on some days\n",
        "final_df['game_workload'].fillna(0, inplace=True)\n",
        "\n",
        "##############\n",
        "# PIVOT TABLE\n",
        "##############\n",
        "\n",
        "def reshape_athlete_data(df):\n",
        "    reshaped_df = df.pivot_table(\n",
        "        index=['athlete_id', 'date', 'game_workload', 'injuries_status'],\n",
        "        columns='metric',\n",
        "        values='value'\n",
        "    ).reset_index()\n",
        "    reshaped_df.columns.name = None\n",
        "    column_order = ['athlete_id', 'date', 'hip_mobility', 'groin_squeeze',\n",
        "                    'game_workload', 'injuries_status']\n",
        "\n",
        "    return reshaped_df[column_order]\n",
        "\n",
        "pivot_df = reshape_athlete_data(final_df)"
      ],
      "metadata": {
        "id": "0losLZYRc_W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# FEATURE ENGINEERING\n",
        "#####################\n",
        "\n",
        "pivot_df[\"injuries_status\"] = pivot_df[\"injuries_status\"].map({\"non_injured\": 0, \"injured\": 1})\n",
        "\n",
        "\n",
        "\n",
        "def calculate_resting_days(group):\n",
        "    resting_days = []\n",
        "    current_resting = 0\n",
        "    for workload in group['game_workload']:\n",
        "        if workload == 0:\n",
        "            current_resting += 1\n",
        "            resting_days.append(current_resting)\n",
        "        else:\n",
        "            current_resting = 0\n",
        "            resting_days.append(current_resting)\n",
        "\n",
        "    return resting_days\n",
        "\n",
        "pivot_df['resting'] = pivot_df.groupby('athlete_id').apply(calculate_resting_days).explode().reset_index(level=0, drop=True).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_injury_risk_features(df):\n",
        "    # Workload-Based Features\n",
        "    df['workload_7d'] = df.groupby('athlete_id')['game_workload'].rolling(7, min_periods=1).sum().reset_index(0, drop=True)\n",
        "\n",
        "    # Acute/Chronic workload ratio (Last 7 days / Last 28 days average)\n",
        "    df['acwr'] = df.groupby('athlete_id')['game_workload'].rolling(7, min_periods=1).mean().reset_index(0, drop=True) / \\\n",
        "                         df.groupby('athlete_id')['game_workload'].rolling(28, min_periods=1).mean().reset_index(0, drop=True)\n",
        "\n",
        "    # Workload change rate (daily)\n",
        "    df['workload_change'] = df.groupby('athlete_id')['game_workload'].pct_change()\n",
        "\n",
        "\n",
        "    # Number of rest days (last 7 days)\n",
        "    df['rest_days_7d'] = df.groupby('athlete_id')['resting'].rolling(7, min_periods=1).sum().reset_index(0, drop=True)\n",
        "\n",
        "    # Mobility trend analysis\n",
        "    df['hip_trend'] = df.groupby('athlete_id')['hip_mobility'].rolling(7, min_periods=1).mean().reset_index(0, drop=True)\n",
        "    df['hip_change'] = df.groupby('athlete_id')['hip_mobility'].pct_change()\n",
        "\n",
        "    df['groin_trend'] = df.groupby('athlete_id')['groin_squeeze'].rolling(7, min_periods=1).mean().reset_index(0, drop=True)\n",
        "    df['groin_change'] = df.groupby('athlete_id')['groin_squeeze'].pct_change()\n",
        "\n",
        "\n",
        "    # Number of injuries in the last 30 days\n",
        "    df['injuries_30d'] = df.groupby('athlete_id')['injuries_status'].rolling(30, min_periods=1).sum().reset_index(0, drop=True)\n",
        "\n",
        "    # Number of days since the last injury\n",
        "    df['days_since_injury'] = df.groupby('athlete_id')['injuries_status'].apply(\n",
        "        lambda x: x.replace({1: 0}).groupby((x != 0).cumsum()).cumcount()\n",
        "    ).reset_index(0, drop=True)\n",
        "\n",
        "    # Workload risk score\n",
        "    df['workload_risk'] = (df['workload_7d'] - df['workload_7d'].mean()) / df['workload_7d'].std()\n",
        "    df['workload_risk'] = 1 / (1 + np.exp(-df['workload_risk']))\n",
        "\n",
        "    # Overall risk score\n",
        "    df['overall_risk'] = (\n",
        "        df['workload_risk'] * 0.2 +\n",
        "        (1 - df['hip_trend'].clip(0, 1)) * 0.2 +\n",
        "        (1 - df['groin_trend'].clip(0, 1)) * 0.2 +\n",
        "        (df['injuries_30d'] > 0).astype(float) * 0.2 +\n",
        "        (1 - df['rest_days_7d'] / 7) * 0.2\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "pivot_df = create_injury_risk_features(pivot_df)\n",
        "\n",
        "\n",
        "\n",
        "#def fill_missing_values(df):\n",
        "    #numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    #for col in numeric_cols:\n",
        "       # df[col] = df.groupby('athlete_id')[col].transform(lambda x: x.fillna(x.median()))\n",
        "      #  df[col] = df[col].fillna(df[col].median())\n",
        "   # return df\n",
        "\n",
        "# Missing values\n",
        "pivot_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "pivot_df = pivot_df.fillna(method='bfill').fillna(method='ffill')"
      ],
      "metadata": {
        "id": "Yjxi7SovCTN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########\n",
        "# EXPORT\n",
        "########\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Injury Prediction/final_data.csv\"\n",
        "pivot_df.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "NRE33FSXMgEF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}